{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sunfish Masked Diffusion — Colab TPU Training\n",
        "\n",
        "This notebook is TPU-only. In Colab: **Runtime → Change runtime type → TPU**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "tpu_addr = os.environ.get(\"COLAB_TPU_ADDR\")\n",
        "print(\"COLAB_TPU_ADDR:\", tpu_addr)\n",
        "\n",
        "try:\n",
        "    import torch_xla\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    print(\"XLA devices:\", xm.get_xla_supported_devices())\n",
        "except Exception as exc:\n",
        "    raise SystemExit(\"torch_xla not available. Switch runtime to TPU and restart.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clone repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm -rf /content/Sunfish\n",
        "!git clone https://github.com/Sculptor-AI/Sunfish /content/Sunfish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install dependencies (skip torch on TPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/Sunfish\n",
        "!pip -q install \"pytorch-lightning>=2.1.0\" \"transformers>=4.40.0\" \"accelerate>=0.27.0\" \"datasets>=2.16.0\" \"numpy>=1.24.0\" \"tqdm>=4.66.0\" \"wandb>=0.16.0\" \"tensorboard>=2.15.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Mount Google Drive for checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Persist checkpoints to Drive\n",
        "This replaces `checkpoints/` with a Drive-backed folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "drive_root = \"/content/drive/MyDrive\"\n",
        "drive_ckpt = f\"{drive_root}/sunfish_checkpoints\"\n",
        "ckpt_path = \"/content/Sunfish/checkpoints\"\n",
        "if os.path.isdir(drive_root):\n",
        "    os.makedirs(drive_ckpt, exist_ok=True)\n",
        "    if os.path.islink(ckpt_path):\n",
        "        os.unlink(ckpt_path)\n",
        "    elif os.path.exists(ckpt_path):\n",
        "        shutil.rmtree(ckpt_path)\n",
        "    os.symlink(drive_ckpt, ckpt_path)\n",
        "    print(f\"Checkpoints -> {drive_ckpt}\")\n",
        "else:\n",
        "    print(\"Drive not mounted, skipping checkpoint symlink.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train on TPU (OpenWebText)\n",
        "Adjust `--max-steps` to fit your Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/Sunfish\n",
        "!python train_masked.py --tpu --dataset openwebtext --max-steps 10000 --checkpoint-every 1000 --overwrite-last --accumulate 16 --num-workers 0 --save-top-k 2 --name colab-tpu-owt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resume training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/Sunfish\n",
        "!python train_masked.py --tpu --resume checkpoints/masked/last.ckpt --dataset openwebtext --max-steps 20000 --checkpoint-every 1000 --overwrite-last --accumulate 16 --num-workers 0 --save-top-k 2 --name colab-tpu-owt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample (runs on CPU in TPU runtime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/Sunfish\n",
        "!python sample_masked.py checkpoints/masked/last.ckpt --mode infill --text \"Q: The opposite of hot is [MASK].\" --infill-len 1 --num-steps 150 --temperature 0.6 --top-k 10"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
